{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Siemese network.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4oP1z9rThbl"
      },
      "source": [
        "Source to following code: https://pythonprogramming.net/convolutional-neural-network-deep-learning-python-tensorflow-keras/\n",
        "<br>\n",
        "Second source is: https://towardsdatascience.com/deeppicar-part-5-lane-following-via-deep-learning-d93acdce6110"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqbtLkl9aV7l"
      },
      "source": [
        "# mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQL2HHfUaoTa"
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32qFOSQcS-o3"
      },
      "source": [
        "%reset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbONPD1gaqeB"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.models import load_model\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import statistics\n",
        "import gc # Helps to clear up some ram\n",
        "\n",
        "import cv2\n",
        "from numpy import random\n",
        "from imgaug import augmenters as img_aug\n",
        "\n",
        "import math\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qa9Be4Gza57a"
      },
      "source": [
        "tf.random.set_seed(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8CXsMZ8bLhy"
      },
      "source": [
        "import pickle\n",
        "\n",
        "path = \"/content/drive/My Drive/AutonomousDriving\"\n",
        "pickle_in = open(path+\"/trainColour.pickle\",\"rb\")\n",
        "# Remove binary version\n",
        "trainImagesAndLabels = pickle.load(pickle_in)\n",
        "\n",
        "imageId = []\n",
        "X = []\n",
        "y_angle = []\n",
        "y_speed = []\n",
        "for id,image,lbl_angle,lbl_speed in trainImagesAndLabels:\n",
        "  #checking = image\n",
        "  if np.count_nonzero(pd.isnull(image)): \n",
        "    print(\"NA: This image was not read well so we will skip for now\")\n",
        "  else:\n",
        "    imageId.append(id)\n",
        "    X.append(image)\n",
        "    y_angle.append(lbl_angle)\n",
        "    y_speed.append(lbl_speed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DN4f-rGJML0l"
      },
      "source": [
        "Standard deviation of the angles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AI1Gn6MeNBIe"
      },
      "source": [
        "# plt.hist(y_speed)\n",
        "# statistics.stdev(y_speed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRL3lMMfbwZa"
      },
      "source": [
        "def pan(image):\n",
        "    # pan left / right / up / down about 10%\n",
        "    pan = img_aug.Affine(translate_percent= {\"x\" : (-0.1, 0.1), \"y\": (-0.1, 0.1)})\n",
        "    image = pan.augment_image(image)\n",
        "    return image\n",
        "    \n",
        "def zoom(image):\n",
        "    zoom = img_aug.Affine(scale=(1, 1.3))  # zoom from 100% (no zoom) to 130%\n",
        "    image = zoom.augment_image(image)\n",
        "    return image\n",
        "\n",
        "def adjust_brightness(image):\n",
        "    # increase or decrease brightness by 30%\n",
        "    brightness = img_aug.Multiply((0.7, 1.3))\n",
        "    image = brightness.augment_image(image)\n",
        "    return image\n",
        "\n",
        "def blur(image):\n",
        "    kernel_size = random.randint(1, 5)  # kernel larger than 5 would make the image way too blurry\n",
        "    image = cv2.blur(image,(kernel_size, kernel_size))\n",
        "   \n",
        "    return image\n",
        "\n",
        "\n",
        "def random_flip(image,speed):\n",
        "    is_flip = random.randint(0, 1)\n",
        "    if is_flip == 1:\n",
        "        # randomly flip horizon\n",
        "        image = cv2.flip(image,1)\n",
        "        \n",
        "   \n",
        "    return image, speed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-k9m29RzXlVg"
      },
      "source": [
        "def random_augment(image, speed, angle):\n",
        "  \n",
        "    if np.random.rand() < 0.5:\n",
        "        image = pan(image)\n",
        "    if np.random.rand() < 0.5:\n",
        "        image = zoom(image)\n",
        "    if np.random.rand() < 0.5:\n",
        "        image = blur(image)\n",
        "    if np.random.rand() < 0.5:\n",
        "        image = adjust_brightness(image)\n",
        "    image, speed = random_flip(image, speed)\n",
        "    \n",
        "    return image, speed, angle\n",
        "# imageId = np.array(imageId)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8NzgqqfXmdj"
      },
      "source": [
        "smallSpeeds=(np.where(np.array(y_speed)<0.5)[0])\n",
        "# # # bigSpeeds=(np.where(np.array(y_speed)>0.5)[0])\n",
        "\n",
        "\n",
        "augmentedImages = []\n",
        "augmentedSpeed = []\n",
        "augmentedAngle = []\n",
        "augmentedID = []\n",
        "# # for idx in bigSpeeds:\n",
        "# #     for _ in range(1):\n",
        "# #       image, speed = random_augment(X[idx], y_speed[idx])\n",
        "# #       augmentedImages.append(image)\n",
        "# #       augmentedSpeed.append(speed)\n",
        "# #       augmentedID.append(imageId[idx])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4vwUFT_0osZ"
      },
      "source": [
        "len(y_angle)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_W1wyaojEjC"
      },
      "source": [
        "for _ in [1,2,3]:\n",
        "  for idx in smallSpeeds:\n",
        "      image, speed, angle = random_augment(X[idx], y_speed[idx], y_angle[idx])\n",
        "      augmentedImages.append(image)\n",
        "      augmentedSpeed.append(speed)\n",
        "      augmentedAngle.append(angle)\n",
        "      augmentedID.append(imageId[idx])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNG3bBHRdwWd"
      },
      "source": [
        "Hist before augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WIHzvBWdvIj"
      },
      "source": [
        "plt.hist(y_speed)\n",
        "# statistics.stdev(y_speed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhRi4RcWd18_"
      },
      "source": [
        "Hist after augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMUzEaSdd1SD"
      },
      "source": [
        "for idx in range(len(augmentedSpeed)):\n",
        "  y_speed.append(augmentedSpeed[idx])\n",
        "  y_angle.append(augmentedAngle[idx])\n",
        "  X.append(augmentedImages[idx])\n",
        "  imageId.append(augmentedID[idx])\n",
        "del augmentedImages\n",
        "del augmentedSpeed\n",
        "del augmentedAngle\n",
        "del augmentedID\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofJ9GNwQfWUV"
      },
      "source": [
        "plt.hist(np.array(y_speed))\n",
        "# statistics.stdev(y_speed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UopdowkSSTNi"
      },
      "source": [
        "X_new = X\n",
        "y_speed_new = y_speed\n",
        "idImage = imageId\n",
        "del X\n",
        "del y_speed\n",
        "del imageId\n",
        "del pickle_in"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CesI0uwdNNAh"
      },
      "source": [
        "print(idImage[-1])\n",
        "print(y_speed_new[-1])\n",
        "plt.imshow(X_new[-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZN9lKo_lXYq"
      },
      "source": [
        "# print(len(X_new))\n",
        "# print(len(y_angle_new))\n",
        "# print(len(idImage))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11h4n49QZ8Aw"
      },
      "source": [
        "X_new = np.array(X_new)\n",
        "y_speed_new = np.array(y_speed_new)\n",
        "idImage = np.array(idImage)\n",
        "# print(X_new.shape)\n",
        "# print(y_angle_new.shape)\n",
        "# print(idImage.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irHogzFCABqi"
      },
      "source": [
        "print(idImage[-1])\n",
        "print(y_speed_new[-1])\n",
        "plt.imshow(X_new[-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itULCrLif3_4"
      },
      "source": [
        "Shuffle the two X_new and y_angle arrays. Note that sklearn shuffle allows us to shuffle two arrays as they were together"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsr6OUWipy7l"
      },
      "source": [
        "Preprocces images to scale, normalize change RGB to YUV and add gaussian noise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-Fy5sMpE01m"
      },
      "source": [
        "def img_preprocess(image):\n",
        "    height, width, _ = image.shape\n",
        "\n",
        "    # in the case that there exists an object in the image of interest DO NOT MAKE reduce the height of the image!!\n",
        "    \n",
        "    image = image[80:240,:,:]  # remove top half of the image, as it is not relevant for lane following\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)  # Nvidia model said it is best to use YUV color space\n",
        "    # image = cv2.GaussianBlur(image, (3,3), 0) # Gaussian Noise / filtering\n",
        "    # image = cv2.resize(image, (240,114))# Need to reduce  size to conserve memory\n",
        "    image = cv2.resize(image, (0,0), fx=0.6, fy=0.6)# Need to reduce  size to conserve memory\n",
        "    image = image / 255 # normalizing\n",
        "    # Round everything into the image to 1 decimal place\n",
        "    image = np.around(image ,2)\n",
        "    return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhzE5GJiEQck"
      },
      "source": [
        "# img = cv2.resize(X_new[0], (240,113))\n",
        "# plt.imshow(img)\n",
        "plt.imshow(X_new[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDoXePYSTT64"
      },
      "source": [
        "plt.imshow(X_new[0][80:240,:,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OT1SFgJZfDM-"
      },
      "source": [
        "# Split before preprocess to object detect"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buCSitc1fCk8"
      },
      "source": [
        "X_image_train_temp, X_image_test_temp, X_angle_train, X_angle_test, y_train, y_test = train_test_split(X_new, y_angle, y_speed_new, test_size=0.1, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpvzuI54-ldz"
      },
      "source": [
        "del X_new"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbEbCzQKfCoJ"
      },
      "source": [
        "X_test_normal = X_image_test_temp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9jzwd8RfjRH"
      },
      "source": [
        "X_train = []\n",
        "for img_index in range(X_image_train_temp.shape[0] ):\n",
        "  X_f = img_preprocess(X_image_train_temp[img_index,:,:,:])\n",
        "  X_train.append(X_f)\n",
        "X_image_train = np.array(X_train)\n",
        "\n",
        "X_test = []\n",
        "for img_index in range(X_image_test_temp.shape[0] ):\n",
        "  X_f = img_preprocess(X_image_test_temp[img_index,:,:,:])\n",
        "  X_test.append(X_f)\n",
        "X_image_test = np.array(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q77BLUDY_hBl"
      },
      "source": [
        "del X_test\n",
        "del X_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "II_uY56MpqJK"
      },
      "source": [
        "# # for idx in range(len(X_new)):\n",
        "# #   if X_new[idx].shape == (240,320,4):\n",
        "# #     X_new[idx] = X_new[idx][:,:,0:3]\n",
        "# X_final = []\n",
        "# for img_index in range(X_new.shape[0] ):\n",
        "#   X_f = img_preprocess(X_new[img_index,:,:,:])\n",
        "#   X_final.append(X_f)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CB1BaRBjrUPn"
      },
      "source": [
        "# X_final = np.array(X_final)\n",
        "# # del X_new\n",
        "# # X_final = np.array(X_final, dtype=np.float16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwsktSnnO5If"
      },
      "source": [
        "# del y_angle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AngAeTNDHAzJ"
      },
      "source": [
        "Create a test dataset to ensure that we do not overfit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoCUio-vBn-R"
      },
      "source": [
        "# print(idImage[0])\n",
        "# print(y_speed_new[0])\n",
        "# plt.imshow(X_final[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tCXVgZHGrMU"
      },
      "source": [
        "# X_train, X_test, y_train, y_test = train_test_split( X_final, y_speed_new, test_size=0.1, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJ5q5JqKOYLI"
      },
      "source": [
        "# y_angle = np.array(y_angle)\n",
        "# X_image_train, X_image_test, X_angle_train, X_angle_test, y_train, y_test = train_test_split(X_final, y_angle, y_speed_new, test_size=0.1, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQSArvBRVDG3"
      },
      "source": [
        "# #shuffle x and y together\n",
        "# perms = np.random.permutation(len(X_final))\n",
        "# X_train = X_final[perms]\n",
        "# y_train = y_speed_new[perms]\n",
        "# idImage = idImage[perms]\n",
        "# del y_speed_new\n",
        "# del X_final"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzmwoMX69ZJh"
      },
      "source": [
        "# plt.imshow(X_train[22])#,:,:,:])\n",
        "# print(y_train[22])\n",
        "# print(idImage[22])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3QsocHmqtdI"
      },
      "source": [
        "X_angle_test = np.array(X_angle_test)\n",
        "X_angle_train = np.array(X_angle_train)\n",
        "\n",
        "\n",
        "tf_y_train = tf.reshape(y_train,[ y_train.shape[0] ,1 ]).numpy()\n",
        "tf_X_angle_train = tf.reshape(X_angle_train,[ X_angle_train.shape[0] ,1 ]).numpy()\n",
        "tf_X_angle_test = tf.reshape(X_angle_test,[ X_angle_test.shape[0] ,1 ]).numpy()\n",
        "print(y_train.shape)\n",
        "print(tf_y_train.shape)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZLg0DAfPSsp"
      },
      "source": [
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZm-86yf9bhD"
      },
      "source": [
        "def angle_feat_model():\n",
        "  # model = Sequential(name='angle input')\n",
        "  input = Input(shape=1)\n",
        "  x= (Dense(1,activation ='relu'))(input)\n",
        "  x = Dense(100,activation ='relu')(x)\n",
        "  # x = Dense(200,activation ='relu')(x)\n",
        "  # x = (Dense(50, activation = 'relu'))(x)\n",
        "  output = x\n",
        "  model = Model(inputs=input,outputs=output)\n",
        "  return model\n",
        "\n",
        "angle_top_model = angle_feat_model()\n",
        "# angle_top_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7NSYkacGPpF"
      },
      "source": [
        "def nvidia_top_model():\n",
        "    \n",
        "    \n",
        "    # elu=Exponential Linear Unit, similar to leaky Relu\n",
        "    # skipping 1st hiddel layer (nomralization layer), as we have normalized the data\n",
        "    \n",
        "    # Convolution Layers\n",
        "    inputs = Input(shape=(X_image_train.shape[1], X_image_train.shape[2], X_image_train.shape[3]))\n",
        "    x = BatchNormalization()(inputs)\n",
        "    x = (Conv2D(24, (5, 5), strides=(2, 2), activation='elu',))(x)#(inputs)# input_shape=(X_train.shape[1], X_train.shape[2], X_train.shape[3]), activation='elu')) \n",
        "    x = (Conv2D(36, (5, 5), strides=(2, 2), activation='elu'))(x)\n",
        "    x = MaxPooling2D(padding='same')(x)\n",
        "    x = (Conv2D(48, (5, 5), strides=(2, 2), activation='elu'))(x)\n",
        "    # x = MaxPooling2D(padding='same')(x)\n",
        "    x = (Conv2D(64, (3, 3), activation='elu'))(x) \n",
        "    #model.add(Dropout(0.2)) # not in original model. added for more robustness\n",
        "    x = (Conv2D(64, (1, 1), activation='elu'))(x)  \n",
        "    \n",
        "    # Fully Connected Layers\n",
        "    x = (Flatten())(x)\n",
        "    x = (Dense(200, activation='elu'))(x)\n",
        "\n",
        "    x = (Dropout(0.1))(x) # not in original model. added for more robustness\n",
        "    x = (Dense(100, activation='elu'))(x)\n",
        "    #model.add(Dense(100, activation='elu'))\n",
        "    # x = (Dropout(0.1))(x)\n",
        "    # x = (Dense(50, activation='elu'))(x)\n",
        "    #model.add(Dense(50, activation='elu'))\n",
        "    #model.add(Dropout(0.05))\n",
        "    # x = (Dense(10, activation='elu'))(x)\n",
        "    outputs = x\n",
        "    #model.add(Dense(10, activation='elu'))\n",
        "    \n",
        "    model = Model(inputs=inputs, outputs=outputs )\n",
        "    return model\n",
        "\n",
        "nvidia_top_model = nvidia_top_model()\n",
        "print(nvidia_top_model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mafl3HpgHPJX",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "from keras.layers import *\n",
        "\n",
        "\n",
        "mergedOut = Add()([nvidia_top_model.output,angle_top_model.output])\n",
        "\n",
        "mergedOut = Flatten()(mergedOut)    \n",
        "# mergedOut = Dense(50, activation='relu')(mergedOut)\n",
        "# mergedOut = Dense(200, activation='elu')(mergedOut)\n",
        "mergedOut = Dense(100, activation='elu')(mergedOut)\n",
        "mergedOut = Dense(50, activation='elu')(mergedOut)\n",
        "mergedOut = Dense(10, activation='elu')(mergedOut)\n",
        "# mergedOut = Dropout(.1)(mergedOut)\n",
        "# mergedOut = Dense(5, activation='relu')(mergedOut)\n",
        "# mergedOut = Dropout(.1)(mergedOut)\n",
        "\n",
        "# output layer\n",
        "mergedOut = Dense(1, activation='sigmoid')(mergedOut)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L19Xol9is3ix"
      },
      "source": [
        "# np.corrcoef(y_angle,y_speed_new)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYWcoHHnH664"
      },
      "source": [
        "from keras.models import Model\n",
        "\n",
        "mergeModel = Model([nvidia_top_model.input, angle_top_model.input], mergedOut)\n",
        "optimizer = Adam(lr=1e-3)\n",
        "mergeModel.compile(loss='binary_crossentropy',\n",
        "                  optimizer=optimizer,               \n",
        "                  metrics=['accuracy'])\n",
        "mergeModel.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTnxM4bMH7-q"
      },
      "source": [
        "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, \n",
        "        patience=7, verbose=1, mode='auto',\n",
        "        restore_best_weights=True)\n",
        "mergeModel.fit([X_image_train,X_angle_train], tf_y_train, batch_size=32, epochs=100, validation_split=0.2,callbacks=[monitor])  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfhcX4F_WnLg"
      },
      "source": [
        "mergeModel.evaluate(x=[X_image_test,X_angle_test],y=y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTCGDtJKFV3N"
      },
      "source": [
        "# def nvidia_model():\n",
        "#\n",
        "#     model = Sequential(name='Nvidia_Model')\n",
        "    \n",
        "#     # elu=Exponential Linear Unit, similar to leaky Relu\n",
        "#     # skipping 1st hiddel layer (nomralization layer), as we have normalized the data\n",
        "    \n",
        "#     # Convolution Layers\n",
        "#     model.add(Conv2D(24, (5, 5), strides=(2, 2), input_shape=(X_train.shape[1], X_train.shape[2], X_train.shape[3]), activation='elu')) \n",
        "#     model.add(Conv2D(36, (5, 5), strides=(2, 2), activation='elu')) \n",
        "#     model.add(Conv2D(48, (5, 5), strides=(2, 2), activation='elu')) \n",
        "#     model.add(Conv2D(64, (3, 3), activation='elu')) \n",
        "#     #model.add(Dropout(0.2)) # not in original model. added for more robustness\n",
        "#     model.add(Conv2D(64, (3, 3), activation='elu'))  \n",
        "    \n",
        "#     # Fully Connected Layers\n",
        "#     model.add(Flatten())\n",
        "#     model.add(Dense(200, activation='elu'))\n",
        "\n",
        "#     model.add(Dropout(0.1)) # not in original model. added for more robustness\n",
        "#     model.add(Dense(100, activation='elu'))\n",
        "#     #model.add(Dense(100, activation='elu'))\n",
        "#     model.add(Dropout(0.1))\n",
        "#     model.add(Dense(50, activation='elu'))\n",
        "#     #model.add(Dense(50, activation='elu'))\n",
        "#     #model.add(Dropout(0.05))\n",
        "#     model.add(Dense(10, activation='elu'))\n",
        "#     #model.add(Dense(10, activation='elu'))\n",
        "    \n",
        "#     # output layer: turn angle (from 45-135, 90 is straight, <90 turn left, >90 turn right)\n",
        "#     model.add(Dense(1, activation='sigmoid')) \n",
        "    \n",
        "#     #optimizer = Adam(lr=1e-7) # lr is learning rate\n",
        "#     optimizer = Adam(lr=1e-3)\n",
        "#     model.compile(loss='binary_crossentropy',\n",
        "#                   optimizer=optimizer,               \n",
        "#                   metrics=['accuracy'])\n",
        "\n",
        "#     return model\n",
        "\n",
        "# model = nvidia_model()\n",
        "# print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5uNaoOaGDcr"
      },
      "source": [
        "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, \n",
        "        patience=7, verbose=1, mode='auto',\n",
        "        restore_best_weights=True)\n",
        "model.fit(X_train, tf_y_train, batch_size=32, epochs=100, validation_split=0.2,callbacks=[monitor])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLC3dAExK2Lm"
      },
      "source": [
        "model.evaluate(x=X_test,y=y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQxlQbJwjjwB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFIjzSI0wRRI"
      },
      "source": [
        "# model.save(os.path.join(path,'Speed_prediction_model.h5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFugzsUCWD6x"
      },
      "source": [
        "speed = model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIiUi8J3xyaP"
      },
      "source": [
        "speed = np.round(speed,0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbdlBSWJeQzQ"
      },
      "source": [
        "bce = tf.keras.metrics.BinaryAccuracy()\n",
        "bce(y_test, speed).numpy()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vGO1_qPlH47"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uk6H5P5kYRvo"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "Object detect for traffic lights and to create data for speed model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3IJkiV6alHy"
      },
      "source": [
        "# %cd \"/content/drive/My Drive/AutonomousDriving/Github/AutonomousCars/Tensorflow/models/research/\"\n",
        "# mainPath = r\"/content/drive/My Drive/AutonomousDriving/Github/AutonomousCars\"\n",
        "# modelPath = mainPath + r\"/Tensorflow/workspace/exported-models/my_model/saved_model\"\n",
        "# labelPath = mainPath + r\"/Tensorflow/workspace/annotations/label_map.pbtxt\"\n",
        "# imgPath = mainPath + r\"/data/test_data/test_data\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixWTjylSq33-"
      },
      "source": [
        "# import tensorflow as tf\n",
        "# import time\n",
        "# from object_detection.utils import label_map_util\n",
        "# from object_detection.utils import visualization_utils as viz_utils\n",
        "# print('Loading model...', end='')\n",
        "# # Load saved model and build the detection function\n",
        "# detect_fn=tf.saved_model.load(modelPath)\n",
        "# print('Done!')\n",
        "# category_index=label_map_util.create_category_index_from_labelmap(labelPath, use_display_name=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nb6e0MDwq7IC"
      },
      "source": [
        "# import numpy as np\n",
        "# from PIL import Image\n",
        "# import matplotlib.pyplot as plt\n",
        "# import warnings\n",
        "# warnings.filterwarnings('ignore')\n",
        "# %matplotlib inline\n",
        "# plt.rcParams.update({'font.size': 12})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivJDYPt9qixQ"
      },
      "source": [
        "# redLightIndexes = []\n",
        "# for idx in range(len(X_test_normal)):\n",
        "#   image = X_test_normal[idx]\n",
        "#   image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "#   input_tensor=tf.convert_to_tensor(image)\n",
        "#   input_tensor=input_tensor[tf.newaxis, ...]\n",
        "#   detections=detect_fn(input_tensor)\n",
        "#   num_detections=int(detections.pop('num_detections'))\n",
        "#   detections={key:value[0,:num_detections].numpy()\n",
        "#                  for key,value in detections.items()}\n",
        "#   detections['num_detections'] = num_detections\n",
        "#   detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "#   #for visualisation uncomment below\n",
        "\n",
        "#   image_np_with_detections=image.copy()\n",
        "#   viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "#         image_np_with_detections,\n",
        "#         detections['detection_boxes'],\n",
        "#         detections['detection_classes'],\n",
        "#         detections['detection_scores'],\n",
        "#         category_index,\n",
        "#         use_normalized_coordinates=True,\n",
        "#         max_boxes_to_draw=100,     \n",
        "#         min_score_thresh=.5,      \n",
        "#         agnostic_mode=False) \n",
        "#   indexes = np.where(detections['detection_scores']>0.5)\n",
        "#   boxes = detections['detection_classes'][indexes]\n",
        "#   if 4 in boxes:\n",
        "#     speed[idx] = 0\n",
        "#     redLightIndexes.append(idx)  \n",
        "#     print(f\"index:{idx} Image ID:\")# {imageId[idx]}\")\n",
        "#   if idx % 50 == 0:\n",
        "#     print(idx)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrdehCHClH77"
      },
      "source": [
        "# bce = tf.keras.metrics.BinaryAccuracy()\n",
        "# bce(y_test, speed).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bW4weL3olH_P"
      },
      "source": [
        "plt.imshow(X_test_normal[17])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKF5Qh9fnhuQ"
      },
      "source": [
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6iHnE1yXBh8"
      },
      "source": [
        "errors = []\n",
        "for i in range(y_test.shape[0]):\n",
        "  if speed[i]-y_test[i] != 0:\n",
        "    errors.append(i)\n",
        "\n",
        "  #print([steering_angle[i][0], tf_y_angle[i][0]])\n",
        "  # print([speed[i][0], y_test[i] ])\n",
        "errors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grVhE1jT-5Mh"
      },
      "source": [
        "len(errors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bp9j7MupBfNs"
      },
      "source": [
        "error = errors[9]\n",
        "plt.imshow(X_test[error]);\n",
        "print(y_test[error])\n",
        "print(speed[error])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUAC8BLCx-P3"
      },
      "source": [
        "x= 0\n",
        "for i in range(y_test.shape[0]):\n",
        "  x += speed[i][0]-y_test[i]\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8DWQcuLXWZa"
      },
      "source": [
        "plt.hist(y_speed_new)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JM8rZ_tsVErl"
      },
      "source": [
        "Calculate the Mean squared error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuMrW57kVDtt"
      },
      "source": [
        "mseSum = 0\n",
        "print(y_test.shape[0])\n",
        "for i in range(y_test.shape[0]):\n",
        "  mseSum += (1/y_test.shape[0] ) *  (steering_angle[i][0] - y_test[i])**2\n",
        "print(mseSum)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prH-bsTHprU2"
      },
      "source": [
        "model.save(os.path.join(path,'Speed_prediction_model.h5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idYlPkdaSN24"
      },
      "source": [
        "del model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sz68hBEbwaSs"
      },
      "source": [
        "Now save the model output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZZEHrtpz4qq"
      },
      "source": [
        ""
      ]
    }
  ]
}